{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyspark.sql import SparkSession \n",
    "from pyspark.ml.feature import RegexTokenizer \n",
    "from pyspark.ml.feature import HashingTF, IDF \n",
    "from pyspark.ml.feature import StopWordsRemover,StringIndexer\n",
    "from pyspark.sql.functions import concat_ws, col\n",
    "from pyspark.ml.classification import LogisticRegression \n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PySpark'ı başlatmak için kullanılan bir SparkSession oluşturuyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-ECOT9SM:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ITC</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2eafadc3ad0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\")\\\n",
    "                            .appName(\"ITC\")\\\n",
    "                            .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veri setini okuyor ve bir DataFrame oluşturuyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+--------------------+\n",
      "|       Kategori|              Başlık|              İçerik|\n",
      "+---------------+--------------------+--------------------+\n",
      "|           Spor|Hakkarigücü Kadın...|Turkcell Kadın Fu...|\n",
      "|Bilim Teknoloji|Uzay raporu: Mars...|Hakemli bilimsel ...|\n",
      "|         Sağlık|Gaziantep Şehir H...|Gaziantep Şehir H...|\n",
      "|         Sağlık|Türkiye sınırın d...|Fırat Kalkanı Har...|\n",
      "|        Ekonomi|3,2 milyar liralı...|Aile ve Sosyal Hi...|\n",
      "|           Spor|Gençler Kılıç Dün...|Eskrimde, Gençler...|\n",
      "|         Sağlık|\"Gıda mühendisind...|\"Mutfakta yapılan...|\n",
      "|           Spor|Michael Schumache...|Formula 1'in ünlü...|\n",
      "|         Eğitim|\"Türkiye ile Güne...|Milli Eğitim Baka...|\n",
      "|     ÖZEL HABER|7 Güzel Adam'ın b...|7 Güzel Adam'ın b...|\n",
      "|         Sağlık|DSÖ, COVID-19'un ...|Dünya Sağlık Örgü...|\n",
      "|           Spor|Kupada son çeyrek...|Ziraat Türkiye Ku...|\n",
      "|         Eğitim|Meslek liselerind...|Milli Eğitim Baka...|\n",
      "|   Kültür-Sanat|Dünyaca ünlü İngi...|Dünyaca ünlü İngi...|\n",
      "|           Spor|Fenerbahçe 90+4’t...|Trendyol Süper Li...|\n",
      "|        Ekonomi|Bakan Şimşek: KİT...|Hazine ve Maliye ...|\n",
      "|Bilim Teknoloji|\"Salmonellayı tes...|\"Çanakkale Onseki...|\n",
      "|           Spor|NBA'de gecenin to...|\"Amerikan Basketb...|\n",
      "|           Spor|Yarım asırlık Mar...|Trendyol 1. Lig'i...|\n",
      "|           Spor|Ajax galibiyeti h...|Tarihinin en başa...|\n",
      "+---------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"DATA/karisik_veri.csv\", inferSchema=True, header=True)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam veri sayısı:  29861\n"
     ]
    }
   ],
   "source": [
    "print(\"Toplam veri sayısı: \", df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kategori sütunundaki eksik değerlerin sayısı:  0\n",
      "Başlık sütunundaki eksik değerlerin sayısı:  91\n",
      "İçerik sütunundaki eksik değerlerin sayısı:  169\n"
     ]
    }
   ],
   "source": [
    "print(\"Kategori sütunundaki eksik değerlerin sayısı: \", df.toPandas()['Kategori'].isnull().sum())\n",
    "print(\"Başlık sütunundaki eksik değerlerin sayısı: \", df.toPandas()['Başlık'].isnull().sum())\n",
    "print(\"İçerik sütunundaki eksik değerlerin sayısı: \", df.toPandas()['İçerik'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=('Başlık'))\n",
    "df = df.dropna(subset=('İçerik'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam veri sayısı:  29692\n"
     ]
    }
   ],
   "source": [
    "print(\"Toplam veri sayısı: \", df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame içindeki \"Başlık\" ve \"İçerik\" adlı sütunlardaki verileri birleştirerek yeni bir \"Text\" sütunu oluşturuyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+\n",
      "|       Kategori|                Text|\n",
      "+---------------+--------------------+\n",
      "|           Spor|Hakkarigücü Kadın...|\n",
      "|Bilim Teknoloji|Uzay raporu: Mars...|\n",
      "|         Sağlık|Gaziantep Şehir H...|\n",
      "|         Sağlık|Türkiye sınırın d...|\n",
      "|        Ekonomi|3,2 milyar liralı...|\n",
      "|           Spor|Gençler Kılıç Dün...|\n",
      "|         Sağlık|\"Gıda mühendisind...|\n",
      "|           Spor|Michael Schumache...|\n",
      "|         Eğitim|\"Türkiye ile Güne...|\n",
      "|     ÖZEL HABER|7 Güzel Adam'ın b...|\n",
      "+---------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"Text\", concat_ws(\" \", \"Başlık\", 'İçerik'))\n",
    "\n",
    "df = df.select('Kategori', 'Text')\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RegexTokenizer kullanarak metin verilerini belirli bir desene göre parçalara ayırarak kelimeleri liste halinde elde ediyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+--------------------+\n",
      "|       Kategori|                Text|               words|\n",
      "+---------------+--------------------+--------------------+\n",
      "|           Spor|Hakkarigücü Kadın...|[hakkarigücü, kad...|\n",
      "|Bilim Teknoloji|Uzay raporu: Mars...|[uzay, raporu, ma...|\n",
      "|         Sağlık|Gaziantep Şehir H...|[gaziantep, şehir...|\n",
      "|         Sağlık|Türkiye sınırın d...|[türkiye, sınırın...|\n",
      "|        Ekonomi|3,2 milyar liralı...|[3, 2, milyar, li...|\n",
      "+---------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(\"words\")\n",
    "\n",
    "tokenizer = RegexTokenizer(inputCol=\"Text\", outputCol=\"words\",pattern=\"\\\\s+|[,.;!?\\\\\\\\-]+|(?<!\\\\\\\\d)-|-(?!\\\\\\\\d)|[^\\\\w\\\\d\\\\u0130\\\\u0131\\\\u00c7\\\\u00e7\\\\u011e\\\\u011f\\\\u015e\\\\u015f\\\\u00d6\\\\u00f6\\\\u00dc\\\\u00fc]+\")\n",
    "\n",
    "df = tokenizer.transform(df)\n",
    "\n",
    "df.select(['Kategori','Text', 'words']).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doğal dil işlemede sıklıkla kullanılan nltk kütüphanesinden Türkçe stop words'leri (durak kelimeleri) çekiyoruz.\n",
    "Örneğin \"acaba ama aslında ve birkaç biz şey gibi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ereny\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "turkish_stopwords = stopwords.words(\"turkish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metindeki durak kelimeleri çıkararak metnin daha anlamlı kısımlarına odaklanmayı sağlıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+--------------------+--------------------+\n",
      "|       Kategori|                Text|               words|      filtered_words|\n",
      "+---------------+--------------------+--------------------+--------------------+\n",
      "|           Spor|Hakkarigücü Kadın...|[hakkarigücü, kad...|[hakkarigücü, kad...|\n",
      "|Bilim Teknoloji|Uzay raporu: Mars...|[uzay, raporu, ma...|[uzay, raporu, ma...|\n",
      "|         Sağlık|Gaziantep Şehir H...|[gaziantep, şehir...|[gaziantep, şehir...|\n",
      "|         Sağlık|Türkiye sınırın d...|[türkiye, sınırın...|[türkiye, sınırın...|\n",
      "|        Ekonomi|3,2 milyar liralı...|[3, 2, milyar, li...|[3, 2, milyar, li...|\n",
      "+---------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(\"filtered_words\")\n",
    "\n",
    "stopwords_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\", stopWords=turkish_stopwords)\n",
    "df = stopwords_remover.transform(df)\n",
    "df .select([ 'Kategori' , 'Text' , 'words' , 'filtered_words' ]).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hashing Term Frequency dönüştürücüsünü kullanarak veri setindeki kelimelerin frekanslarını hesaplıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"raw_features\")\n",
    "hashing_tf = HashingTF(inputCol=\"filtered_words\",\n",
    "                       outputCol=\"raw_features\", \n",
    "                       numFeatures=10000) # Deneme yanılma ile bulunur..\n",
    "\n",
    "featurized_data = hashing_tf.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF, bir belgedeki bir kelimenin önemini ölçen bir istatistiksel değerdir. Bu değer, bir kelimenin bir belgedeki sıklığını (TF) ve tüm belgelerdeki görünüm sıklığını (IDF) dikkate alarak hesaplanır. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|       Kategori|                Text|               words|      filtered_words|            features|\n",
      "+---------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|           Spor|Hakkarigücü Kadın...|[hakkarigücü, kad...|[hakkarigücü, kad...|(10000,[317,580,6...|\n",
      "|Bilim Teknoloji|Uzay raporu: Mars...|[uzay, raporu, ma...|[uzay, raporu, ma...|(10000,[134,202,3...|\n",
      "|         Sağlık|Gaziantep Şehir H...|[gaziantep, şehir...|[gaziantep, şehir...|(10000,[86,746,81...|\n",
      "|         Sağlık|Türkiye sınırın d...|[türkiye, sınırın...|[türkiye, sınırın...|(10000,[527,679,9...|\n",
      "|        Ekonomi|3,2 milyar liralı...|[3, 2, milyar, li...|[3, 2, milyar, li...|(10000,[474,503,1...|\n",
      "|           Spor|Gençler Kılıç Dün...|[gençler, kılıç, ...|[gençler, kılıç, ...|(10000,[903,1318,...|\n",
      "|         Sağlık|\"Gıda mühendisind...|[gıda, mühendisin...|[gıda, mühendisin...|(10000,[139,886,9...|\n",
      "|           Spor|Michael Schumache...|[michael, schumac...|[michael, schumac...|(10000,[137,1407,...|\n",
      "|         Eğitim|\"Türkiye ile Güne...|[türkiye, ile, gü...|[türkiye, güney, ...|(10000,[393,490,5...|\n",
      "|     ÖZEL HABER|7 Güzel Adam'ın b...|[7, güzel, adam, ...|[7, güzel, adam, ...|(10000,[73,250,97...|\n",
      "|         Sağlık|DSÖ, COVID-19'un ...|[dsö, covıd, 19, ...|[dsö, covıd, 19, ...|(10000,[181,280,3...|\n",
      "|           Spor|Kupada son çeyrek...|[kupada, son, çey...|[kupada, son, çey...|(10000,[209,953,2...|\n",
      "|         Eğitim|Meslek liselerind...|[meslek, liseleri...|[meslek, liseleri...|(10000,[1265,1412...|\n",
      "|   Kültür-Sanat|Dünyaca ünlü İngi...|[dünyaca, ünlü, i...|[dünyaca, ünlü, i...|(10000,[323,584,1...|\n",
      "|           Spor|Fenerbahçe 90+4’t...|[fenerbahçe, 90, ...|[fenerbahçe, 90, ...|(10000,[304,1152,...|\n",
      "|        Ekonomi|Bakan Şimşek: KİT...|[bakan, şimşek, k...|[bakan, şimşek, k...|(10000,[128,302,3...|\n",
      "|Bilim Teknoloji|\"Salmonellayı tes...|[salmonellayı, te...|[salmonellayı, te...|(10000,[318,832,1...|\n",
      "|           Spor|NBA'de gecenin to...|[nba, de, gecenin...|[nba, gecenin, to...|(10000,[526,879,1...|\n",
      "|           Spor|Yarım asırlık Mar...|[yarım, asırlık, ...|[yarım, asırlık, ...|(10000,[69,156,33...|\n",
      "|           Spor|Ajax galibiyeti h...|[ajax, galibiyeti...|[ajax, galibiyeti...|(10000,[417,831,1...|\n",
      "+---------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "\n",
    "idf_vectorizer = idf.fit(featurized_data)\n",
    "\n",
    "rescaled_data = idf_vectorizer.transform(featurized_data)\n",
    "\n",
    "rescaled_data.select(\"Kategori\",'Text', 'words', 'filtered_words', \"features\").show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kategori sütununu sayısal tipe dönüştürüyoruz.\n",
    "Spor -> 0 , Eğitim -> 1 , Ekonomi -> 2 , Sağlık -> 3 , Kültür-Sanat -> 4 , Bilim Teknoloji -> 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"Kategori\", outputCol=\"label\")\n",
    "\n",
    "rescaled_data = indexer.fit(rescaled_data).transform(rescaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veri setini eğitim ve test olmak üzere bölüyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eğitim Veri seti Sayısı: 22227\n",
      "Test Veri seti Sayısı: 7465\n"
     ]
    }
   ],
   "source": [
    "(train, test) = rescaled_data.randomSplit([0.75, 0.25], seed = 202)\n",
    "print(\"Eğitim Veri seti Sayısı: \" + str(train.count()))\n",
    "print(\"Test Veri seti Sayısı: \" + str(test.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Çok sınıflı (multinomial) bir Lojistik Regresyon modeli oluşturuyor ve eğitiyoruz. Daha sonra, bu modeli kullanarak test veri seti üzerinde tahminler yaparak tahmin sonuçlarını içeren bir DataFrame oluşturuyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+---------------+\n",
      "|                Text|         probability|prediction|       Kategori|\n",
      "+--------------------+--------------------+----------+---------------+\n",
      "|\"\"\"100 bin dolara...|[0.04153611058084...|       5.0|Bilim Teknoloji|\n",
      "|\"\"\"Ateş Şövalyesi...|[0.06824226459827...|       5.0|Bilim Teknoloji|\n",
      "|\"\"\"Bir Adam Yarat...|[0.00910351432343...|       4.0|Bilim Teknoloji|\n",
      "|\"\"\"Sifon çekmek C...|[0.02571815846943...|       3.0|Bilim Teknoloji|\n",
      "|\"\"\"TCG Batıray\"\" ...|[0.17680872832889...|       5.0|Bilim Teknoloji|\n",
      "|\"\"\"Take Off İstan...|[0.11833692461738...|       5.0|Bilim Teknoloji|\n",
      "|\"\"\"Tapu Güvenilir...|[0.04031760668706...|       2.0|Bilim Teknoloji|\n",
      "|\"\"\"Türkiye siber ...|[0.09402042515622...|       5.0|Bilim Teknoloji|\n",
      "|\"Antarktika'da \"\"...|[0.02948844698268...|       5.0|Bilim Teknoloji|\n",
      "|\"Avrupa'nın \"\"bul...|[0.08606331739154...|       4.0|Bilim Teknoloji|\n",
      "|\"Belki şurada küç...|[0.06545644932865...|       5.0|Bilim Teknoloji|\n",
      "|\"Botlar, \"\"Ben ro...|[0.04110431284550...|       5.0|Bilim Teknoloji|\n",
      "|\"Cumhuriyetin 100...|[0.04490004762632...|       5.0|Bilim Teknoloji|\n",
      "|\"Dünya yarın \"\"Sü...|[0.20138392956863...|       5.0|Bilim Teknoloji|\n",
      "|\"Dünyada 2,9 mily...|[0.06850605467409...|       5.0|Bilim Teknoloji|\n",
      "|\"Dünyanın en hızl...|[0.08179893269733...|       3.0|Bilim Teknoloji|\n",
      "|\"Eski garajı bili...|[0.02756251342482...|       5.0|Bilim Teknoloji|\n",
      "|\"Kamikaze İHA \"\"D...|[0.04145471500764...|       5.0|Bilim Teknoloji|\n",
      "|\"Maymunlar \"\"düşü...|[0.03636596381617...|       5.0|Bilim Teknoloji|\n",
      "|\"Milli uçak proje...|[0.01877064671909...|       5.0|Bilim Teknoloji|\n",
      "+--------------------+--------------------+----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(featuresCol='features',\n",
    "                        labelCol='label',\n",
    "                        family=\"multinomial\",\n",
    "                        regParam=0.3,\n",
    "                        elasticNetParam=0,\n",
    "                        maxIter=50)\n",
    "\n",
    "lrModel = lr.fit(train)\n",
    "\n",
    "predictions = lrModel.transform(test)\n",
    "\n",
    "predictions.select(\"Text\", 'probability','prediction', 'Kategori').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-seti doğruluğu :  0.8694675560211187\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "\n",
    "print(\"Test-seti doğruluğu : \", evaluator.evaluate(predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
